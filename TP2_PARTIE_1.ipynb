{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 2. PARTIE 1. scikit-learn + Naive Bayes\n",
    "\n",
    "<img src=\"http://media.giphy.com/media/2lbhL8dSGMh8I/giphy.gif\"  width=\"200\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le module de Machine Learning en Python : scitkit-learn (sklearn)\n",
    "http://scikit-learn.org/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan :\n",
    "\n",
    "   [- Iris dataset](#1)\n",
    "   \n",
    "   [- Naive Bayes](#2)\n",
    "   \n",
    "   [- Mon Naive Bayes](#3)\n",
    "   \n",
    "   [- Tests](#4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://78.media.tumblr.com/ec97315a70ebd605ac05f3b91feadaa5/tumblr_monmpxBfcM1qirapio1_500.gif\" width = 200>\n",
    "<a id=\"1\"></a> \n",
    " \n",
    "# 1. Iris dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va chercher le dataset **iris** dans le module sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DESCR': 'Iris Plants Database\\n====================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML iris datasets.\\nhttp://archive.ics.uci.edu/ml/datasets/Iris\\n\\nThe famous Iris database, first used by Sir R.A Fisher\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\nReferences\\n----------\\n   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...\\n',\n",
       " 'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='|S10')}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iris Plants Database\\n====================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML iris datasets.\\nhttp://archive.ics.uci.edu/ml/datasets/Iris\\n\\nThe famous Iris database, first used by Sir R.A Fisher\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\nReferences\\n----------\\n   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://media.giphy.com/media/c1zviFHCf4pq0/giphy.gif\" width = 200>\n",
    "<a id=\"2\"></a> \n",
    " \n",
    "# 2. Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GaussianNB in module sklearn.naive_bayes:\n",
      "\n",
      "class GaussianNB(BaseNB)\n",
      " |  Gaussian Naive Bayes (GaussianNB)\n",
      " |  \n",
      " |  Can perform online updates to model parameters via `partial_fit` method.\n",
      " |  For details on algorithm used to update feature means and variance online,\n",
      " |  see Stanford CS tech report STAN-CS-79-773 by Chan, Golub, and LeVeque:\n",
      " |  \n",
      " |      http://i.stanford.edu/pub/cstr/reports/cs/tr/79/773/CS-TR-79-773.pdf\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <gaussian_naive_bayes>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  priors : array-like, shape (n_classes,)\n",
      " |      Prior probabilities of the classes. If specified the priors are not\n",
      " |      adjusted according to the data.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  class_prior_ : array, shape (n_classes,)\n",
      " |      probability of each class.\n",
      " |  \n",
      " |  class_count_ : array, shape (n_classes,)\n",
      " |      number of training samples observed in each class.\n",
      " |  \n",
      " |  theta_ : array, shape (n_classes, n_features)\n",
      " |      mean of each feature per class\n",
      " |  \n",
      " |  sigma_ : array, shape (n_classes, n_features)\n",
      " |      variance of each feature per class\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
      " |  >>> Y = np.array([1, 1, 1, 2, 2, 2])\n",
      " |  >>> from sklearn.naive_bayes import GaussianNB\n",
      " |  >>> clf = GaussianNB()\n",
      " |  >>> clf.fit(X, Y)\n",
      " |  GaussianNB(priors=None)\n",
      " |  >>> print(clf.predict([[-0.8, -1]]))\n",
      " |  [1]\n",
      " |  >>> clf_pf = GaussianNB()\n",
      " |  >>> clf_pf.partial_fit(X, Y, np.unique(Y))\n",
      " |  GaussianNB(priors=None)\n",
      " |  >>> print(clf_pf.predict([[-0.8, -1]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GaussianNB\n",
      " |      BaseNB\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, priors=None)\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit Gaussian Naive Bayes according to X, y\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          Training vectors, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Target values.\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,), optional (default=None)\n",
      " |          Weights applied to individual samples (1. for unweighted).\n",
      " |      \n",
      " |          .. versionadded:: 0.17\n",
      " |             Gaussian Naive Bayes supports fitting with *sample_weight*.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns self.\n",
      " |  \n",
      " |  partial_fit(self, X, y, classes=None, sample_weight=None)\n",
      " |      Incremental fit on a batch of samples.\n",
      " |      \n",
      " |      This method is expected to be called several times consecutively\n",
      " |      on different chunks of a dataset so as to implement out-of-core\n",
      " |      or online learning.\n",
      " |      \n",
      " |      This is especially useful when the whole dataset is too big to fit in\n",
      " |      memory at once.\n",
      " |      \n",
      " |      This method has some performance and numerical stability overhead,\n",
      " |      hence it is better to call partial_fit on chunks of data that are\n",
      " |      as large as possible (as long as fitting in the memory budget) to\n",
      " |      hide the overhead.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          Training vectors, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Target values.\n",
      " |      \n",
      " |      classes : array-like, shape (n_classes,), optional (default=None)\n",
      " |          List of all the classes that can possibly appear in the y vector.\n",
      " |      \n",
      " |          Must be provided at the first call to partial_fit, can be omitted\n",
      " |          in subsequent calls.\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,), optional (default=None)\n",
      " |          Weights applied to individual samples (1. for unweighted).\n",
      " |      \n",
      " |          .. versionadded:: 0.17\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns self.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset([])\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseNB:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Perform classification on an array of test vectors X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape = [n_samples]\n",
      " |          Predicted target values for X\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Return log-probability estimates for the test vector X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array-like, shape = [n_samples, n_classes]\n",
      " |          Returns the log-probability of the samples for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute `classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Return probability estimates for the test vector X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array-like, shape = [n_samples, n_classes]\n",
      " |          Returns the probability of the samples for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute `classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method fit in module sklearn.naive_bayes:\n",
      "\n",
      "fit(self, X, y, sample_weight=None) method of sklearn.naive_bayes.GaussianNB instance\n",
      "    Fit Gaussian Naive Bayes according to X, y\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    X : array-like, shape (n_samples, n_features)\n",
      "        Training vectors, where n_samples is the number of samples\n",
      "        and n_features is the number of features.\n",
      "    \n",
      "    y : array-like, shape (n_samples,)\n",
      "        Target values.\n",
      "    \n",
      "    sample_weight : array-like, shape (n_samples,), optional (default=None)\n",
      "        Weights applied to individual samples (1. for unweighted).\n",
      "    \n",
      "        .. versionadded:: 0.17\n",
      "           Gaussian Naive Bayes supports fitting with *sample_weight*.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    self : object\n",
      "        Returns self.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "help(gnb.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 150 points : 6\n"
     ]
    }
   ],
   "source": [
    "y_pred = gnb.fit(iris.data, iris.target).predict(iris.data)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "       % (iris.data.shape[0],(iris.target != y_pred).sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150L, 4L)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 71,  98,  50, 145,  89,  14,   4,   9, 121, 123, 148,  76,  34,\n",
       "        68,  88,  47,  46, 117, 113,  21,  82, 131,  59,   1, 102, 141,\n",
       "        78,  25,  56,  69, 110,  38,  33,  58,   0,   3,  20,  73, 115,\n",
       "        31,  16,  19,  97,  61, 122, 106, 111,  55,  52,  43,  42,  93,\n",
       "         5,  17,  54,   8,  95, 136,  37, 147,  64, 119, 100, 133, 118,\n",
       "       112,  35,  99,  24, 125,  92, 124, 143,  22, 127])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = np.random.choice(range(150), 75, replace=False)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = range(150)\n",
    "test = np.delete(a, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 1 1 1\n",
      " 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2 = gnb.fit(iris.data[train,], iris.target[train,]).predict(iris.data[test,])\n",
    "print(y_pred2)\n",
    "print(iris.target[test,])\n",
    "(iris.target[test,] != y_pred2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction NB renvoie le pourcentage d'erreur de prédiction du label (les 3 types d'espèce) pour une répétition de nb tirage aléatoire sur un ensemble d'entrainement (train) de taille i (i variant de A à B)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB(A,B,nb):\n",
    "    res = []\n",
    "    for i in range(B-A+1):\n",
    "        temp = 0\n",
    "        for j in range(nb):\n",
    "            train = np.random.choice(range(150), A+i, replace=False)\n",
    "            a = range(150)\n",
    "            test = np.delete(a, train)\n",
    "            y_pred = gnb.fit(iris.data[train,], iris.target[train,]).predict(iris.data[test,])\n",
    "            temp = temp +(iris.target[test,] != y_pred).sum()/(float(len(test)))\n",
    "        res = res + [100*temp/nb]\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xea07400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = 5\n",
    "B = 145\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(np.linspace(A,B,B-A+1), NB(A,B,100));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"http://media3.giphy.com/media/KYMR9VsDGs3PW/giphy.gif\" width = 200>\n",
    "<a id=\"3\"></a> \n",
    " \n",
    "# 3. Mon Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MonNaiveBayes(train, test):\n",
    "    #TARGET\n",
    "    unique, counts = np.unique(train.target, return_counts=True)\n",
    "    freq = counts/float(len(train.target))\n",
    "    dic = dict(zip(unique, freq)) \n",
    "    estimM = np.zeros(shape=(len(unique),train.data.shape[1]))\n",
    "    estimV = np.zeros(shape=(len(unique),train.data.shape[1])) \n",
    "    #DATA : estimation\n",
    "    l = 0\n",
    "    for tar in unique:\n",
    "        estimM[l,] = np.apply_along_axis(np.mean, 0, train.data[train.target == tar,])\n",
    "        estimV[l,] = np.apply_along_axis(np.var, 0, train.data[train.target == tar,])\n",
    "        l = l+1\n",
    "    \n",
    "    choice = np.zeros(shape=(test.data.shape[0],len(unique)))\n",
    "    #DATA : test \n",
    "    for i in range(test.data.shape[0]):\n",
    "        for j in range(len(unique)):\n",
    "            choice[i,j] = -0.5*sum((test.data[i]-estimM[j])*(test.data[i]-estimM[j])/estimV[j]) + np.log(freq[j]) - 0.5*np.log(np.prod(estimV[j,]))\n",
    "    res = np.argmax(choice, axis=1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MonNaiveBayes(iris, iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1\n",
      " 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1\n",
      " 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gnb.fit(iris.data, iris.target).predict(iris.data)\n",
    "y_my_pred = MonNaiveBayes(iris, iris)\n",
    "print(y_pred)\n",
    "print(y_my_pred)\n",
    "(y_pred == y_my_pred).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://media2.giphy.com/media/GgtcDmMa97FhC/200.gif\" width = 200>\n",
    "<a id=\"3\"></a> \n",
    " \n",
    "# 3. Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train = 50\n",
    "\n",
    "iris2 = copy.deepcopy(iris)\n",
    "\n",
    "train = np.random.choice(range(150), nb_train, replace=False)\n",
    "iris2.data = iris2.data[train]\n",
    "iris2.target = iris2.target[train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1\n",
      " 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1\n",
      " 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gnb.fit(iris2.data, iris2.target).predict(iris.data)\n",
    "y_my_pred = MonNaiveBayes(iris2, iris)\n",
    "print(y_pred)\n",
    "print(y_my_pred)\n",
    "(y_pred == y_my_pred).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
